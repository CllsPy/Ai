{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 68699,
          "databundleVersionId": 7659021,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 30664,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "#Baseline #Evaluation #Pipeline",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CllsPy/ML-Competition-Kaggle/blob/main/Playground%20Series%20-%20Season%204%2C%20Episode%203.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'playground-series-s4e3:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-competitions-data%2Fkaggle-v2%2F68699%2F7659021%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240312%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240312T070702Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D88bbc7553f033f31912d705e0f7f1bdf877571763698975fe7aa6da596144704516f0c06a42ab6984ee4a9d5acf056c938408ed8d154d347fe63278ec710d647d4a46dd2e5ad7cb5bbd01a6353ab233cd8524672c794bb8633083c68581004d73930f9733d04bea053de5acb6db2ea575f271d8337e3dd7d7e50682ca86a77dcd5b976a8527561c917353cb6a2ee1443dce794638f0d9f735171b0cedf93b7a860b781222b280438dd99cf4e3761fa6ff5c4739f4340e00683a4d6430bd26b823804d86db2518057e190d6232556cd45ee0a53ab8b5ea7e8bf0790478fd7e22a5822f843dbfd2f14c30e89a272fad01d27164d8f0d87de7d0bffd3fa42c8d80f'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "m5gqKQCxfIdG"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# basics\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "# sckit\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
        "\n",
        "from xgboost.sklearn import XGBClassifier\n",
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.feature_selection import SelectPercentile, chi2\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.preprocessing import PowerTransformer\n",
        "from sklearn.preprocessing import KBinsDiscretizer\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import accuracy_score\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-11T15:53:34.432274Z",
          "iopub.execute_input": "2024-03-11T15:53:34.433082Z",
          "iopub.status.idle": "2024-03-11T15:53:34.444259Z",
          "shell.execute_reply.started": "2024-03-11T15:53:34.433037Z",
          "shell.execute_reply": "2024-03-11T15:53:34.4433Z"
        },
        "trusted": true,
        "id": "PkJbOcL4fIdR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# seed\n",
        "np.random.seed(101)\n",
        "\n",
        "# path\n",
        "URL = '/kaggle/input/playground-series-s4e3/train.csv'\n",
        "\n",
        "# targert\n",
        "TARGET_FEATURES = [\n",
        "\n",
        "                'Pastry',\n",
        "                'Z_Scratch',\n",
        "                'K_Scatch',\n",
        "                'Stains',\n",
        "                'Dirtiness',\n",
        "                'Bumps',\n",
        "                'Other_Faults'\n",
        "    ]\n",
        "\n",
        "\n",
        "# load\n",
        "train = pd.read_csv(URL).set_index('id')\n",
        "\n",
        "# features and labels\n",
        "X = train.drop(TARGET_FEATURES, axis=1)\n",
        "y = train[TARGET_FEATURES]\n",
        "\n",
        "\n",
        "# train and test\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.35)\n",
        "\n",
        "\n",
        "# models\n",
        "models = {\n",
        "\n",
        "        #'lgr': LogisticRegression(max_iter=10000),\n",
        "        #'svm': SVC(),\n",
        "        #'gnb': GaussianNB(),\n",
        "        #'sgd': SGDClassifier(),\n",
        "\n",
        "        'knn': KNeighborsClassifier(),\n",
        "        'rfc': RandomForestClassifier(),\n",
        "        'gbc': GradientBoostingClassifier(),\n",
        "        'lgbm': LGBMClassifier(),\n",
        "        'xgb': XGBClassifier()\n",
        "    }\n",
        "\n",
        "\n",
        "# func for eval\n",
        "def train_eval(models, X_train, X_val, y_train, y_val):\n",
        "    '''\n",
        "    Function to evaluate the\n",
        "    models\n",
        "\n",
        "    models: desired models\n",
        "    X_train: training feature\n",
        "    X_val: validation feature\n",
        "    y_train: training label\n",
        "    y_val: validation label\n",
        "\n",
        "    '''\n",
        "\n",
        "    # pipeline numérico\n",
        "    numeric_features = X.select_dtypes(exclude=['object']).columns\n",
        "    numeric_transformer = Pipeline(\n",
        "        steps=[(\"scaler\", RobustScaler())])\n",
        "\n",
        "    preprocessor = ColumnTransformer(\n",
        "        transformers=[\n",
        "            (\"num\", numeric_transformer, numeric_features),])\n",
        "\n",
        "    models_score = {}\n",
        "    for name, model in models.items():\n",
        "\n",
        "        clf = Pipeline(steps=[(\"preprocessor\", preprocessor),(\"classifier\", model)]) # models w/ fe\n",
        "        treinar = MultiOutputClassifier(clf).fit(X_train, y_train) # models wo/ fe\n",
        "        models_score[name] = treinar.score(X_val, y_val)\n",
        "\n",
        "    return models_score\n",
        "\n",
        "# call func.\n",
        "#train_eval(models, X_train, X_val, y_train, y_val)\n",
        "\n",
        "\n",
        "# Inicializar modelos individuais\n",
        "knn_ens = KNeighborsClassifier()\n",
        "rfc_ens = RandomForestClassifier()\n",
        "gbc_ens = GradientBoostingClassifier()\n",
        "xgb_ens = XGBClassifier()\n",
        "lgbm_ens = LGBMClassifier()\n",
        "\n",
        "# Inicializar o Voting Classifier\n",
        "voting_clf = VotingClassifier(\n",
        "    estimators=[\n",
        "        ('knn', knn_ens),\n",
        "        ('rfc', rfc_ens),\n",
        "        ('gbc', gbc_ens),\n",
        "        ('xgb', xgb_ens),\n",
        "        ('lgbm_ens', lgbm_ens)], voting='hard')\n",
        "\n",
        "# Treinar o Voting Classifier\n",
        "# fit_vc = MultiOutputClassifier(voting_clf).fit(X_train, y_train)\n",
        "\n",
        "numeric_features = X.select_dtypes(exclude=['object']).columns\n",
        "numeric_transformer = Pipeline(\n",
        "    steps=[(\"scaler\", RobustScaler())])\n",
        "\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", numeric_transformer, numeric_features),])\n",
        "\n",
        "clf = Pipeline(steps=[\n",
        "     (\"preprocessor\", preprocessor),\n",
        "                       (\"classifier\", voting_clf)])\n",
        "\n",
        "# Treinar\n",
        "clf_vcl = MultiOutputClassifier(voting_clf).fit(X_train, y_train)\n",
        "\n",
        "# Fazer previsões\n",
        "y_pred = clf_vcl.predict(X_val)\n",
        "\n",
        "# Calcular a acurácia\n",
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "print(\"Acurácia do Voting Classifier:\", accuracy)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-11T16:13:03.072396Z",
          "iopub.execute_input": "2024-03-11T16:13:03.072752Z",
          "iopub.status.idle": "2024-03-11T16:14:09.16614Z",
          "shell.execute_reply.started": "2024-03-11T16:13:03.072723Z",
          "shell.execute_reply": "2024-03-11T16:14:09.165189Z"
        },
        "trusted": true,
        "id": "OnIR6BQJfIdS",
        "outputId": "b7bc45ab-dafc-4517-ccc8-f57a0a74ede2"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "[LightGBM] [Info] Number of positive: 934, number of negative: 11558\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003577 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 5158\n[LightGBM] [Info] Number of data points in the train set: 12492, number of used features: 27\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.074768 -> initscore=-2.515657\n[LightGBM] [Info] Start training from score -2.515657\n[LightGBM] [Info] Number of positive: 771, number of negative: 11721\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003737 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 5158\n[LightGBM] [Info] Number of data points in the train set: 12492, number of used features: 27\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.061720 -> initscore=-2.721449\n[LightGBM] [Info] Start training from score -2.721449\n[LightGBM] [Info] Number of positive: 2245, number of negative: 10247\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003656 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 5158\n[LightGBM] [Info] Number of data points in the train set: 12492, number of used features: 27\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.179715 -> initscore=-1.518279\n[LightGBM] [Info] Start training from score -1.518279\n[LightGBM] [Info] Number of positive: 364, number of negative: 12128\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004643 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 5158\n[LightGBM] [Info] Number of data points in the train set: 12492, number of used features: 27\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.029139 -> initscore=-3.506118\n[LightGBM] [Info] Start training from score -3.506118\n[LightGBM] [Info] Number of positive: 316, number of negative: 12176\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003649 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 5158\n[LightGBM] [Info] Number of data points in the train set: 12492, number of used features: 27\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.025296 -> initscore=-3.651480\n[LightGBM] [Info] Start training from score -3.651480\n[LightGBM] [Info] Number of positive: 3097, number of negative: 9395\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003621 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 5158\n[LightGBM] [Info] Number of data points in the train set: 12492, number of used features: 27\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.247919 -> initscore=-1.109744\n[LightGBM] [Info] Start training from score -1.109744\n[LightGBM] [Info] Number of positive: 4262, number of negative: 8230\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003594 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 5158\n[LightGBM] [Info] Number of data points in the train set: 12492, number of used features: 27\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.341178 -> initscore=-0.658047\n[LightGBM] [Info] Start training from score -0.658047\nAcurácia do Voting Classifier: 0.38575888211684256\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(101)\n",
        "\n",
        "test = pd.read_csv('/kaggle/input/playground-series-s4e3/test.csv').set_index('id')\n",
        "sub = pd.read_csv('/kaggle/input/playground-series-s4e3/sample_submission.csv')\n",
        "sub[TARGET_FEATURES] = clf_vcl.predict(test)\n",
        "sub.to_csv('16__ensemble__fe.csv', index=False)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-11T16:20:47.14062Z",
          "iopub.execute_input": "2024-03-11T16:20:47.141281Z",
          "iopub.status.idle": "2024-03-11T16:20:56.49636Z",
          "shell.execute_reply.started": "2024-03-11T16:20:47.14125Z",
          "shell.execute_reply": "2024-03-11T16:20:56.495521Z"
        },
        "trusted": true,
        "id": "E6OPehWpfIdV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}